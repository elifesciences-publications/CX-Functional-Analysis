{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics and exports\n",
    "In this notebook, we use the results generated by the ```functionalConnectivityRaw.jl``` in jld2 files to calculate a bunch of statistics per pair and export them to a few formats, including ```.js``` files that are underlying the website. This notebook follows the ```code/statsAndExports.jl``` script (exports are commented out as they would be useless in the Binder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the environment\n",
    "We want to be in ```CX-Functional-Analysis```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2,DataFrames,AxisArrays,FileIO,CSV\n",
    "using Interpolations\n",
    "using StatsBase,Distributions\n",
    "using JSON\n",
    "using DataStructures\n",
    "using Distances,Bootstrap\n",
    "using HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"code/functions/fluoRunUtilities.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "We're loading the labbook (as a data frame), the table containing the drivers info and the dataset of the fluorescent traces. The jld2 files are on the OSF framework storage, so we need to interact with their API to get the download links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reqLabbook = HTTP.get(\"https://api.osf.io/v2/nodes/vsa3z/files/osfstorage/?filter[name]=labbookTable.jld2\")\n",
    "labbookLink = JSON.parse(\"$(Char.(reqLabbook.body)...)\")\n",
    "\n",
    "reqData = HTTP.get(\"https://api.osf.io/v2/nodes/vsa3z/files/osfstorage/?filter[name]=rawData.jld2\")\n",
    "rawLink = JSON.parse(\"$(Char.(reqData.body)...)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labbook = load(download(labbookLink[\"data\"][1][\"links\"][\"download\"]),\"labbook\")\n",
    "linesToType = CSV.read(\"LinesAndTypes.csv\",weakrefstrings=false)\n",
    "full_data_dict = load(download(rawLink[\"data\"][1][\"links\"][\"download\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```full_data_dict``` is a dictionary with one entry per experiment (with keys following the naming convention \"jun1417-Fly1-EB\", the last part being the region imaged). Each entry is an array with each element corresponding to one experimental run. Each element is a tuple of :\n",
    "- one AxisArray (the fluorescent traces)\n",
    "- one dictionary of metadata (the stimulus conditions and the time to drug exposure if relevant)\n",
    "\n",
    "The AxisArray : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_dict[\"jun1417-Fly1-EB\"][6][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the metadata :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_dict[\"jun1417-Fly1-EB\"][6][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processed versions of the results\n",
    "We're adding one version of the data that is averaged per run (i.e. the repeats are lumped together) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_data_dict = map(full_data_dict) do full  \n",
    "    (k,full) = full\n",
    "    meanSignals = [(AxisArray(vec(mean(f[1].data,3)),axes(f[1],Axis{:time})),f[2]) for \n",
    "        f in full]\n",
    "    Pair(k,meanSignals)    \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be saved locally (and used in other scripts) : (useless for this Binder as we're loading those files from the OSF usually)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save(\"data/interpolatedData.jld2\",large_interpolated_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a version of the data where the fluorescence is linearly interpolated on a common time grid. This is used to calculate some statistics (for example correlations between flies) or average experiments together. 2 versions are created, one only contains the times around the stimulation (3 to 5 seconds), the other a large chunk of the recordings (1 to 12 seconds) in 100ms increments :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interpolated_data_dict = map(avg_data_dict) do dct\n",
    "        (k,val) = dct\n",
    "        newAvg = [interpolate_run(run,3:0.1:5) for run in val]     ## The two seconds following the stimulation\n",
    "        Pair(k,newAvg)\n",
    "end;\n",
    "\n",
    "large_interpolated_data_dict = map(avg_data_dict) do dct\n",
    "        (k,val) = dct\n",
    "        newAvg = [interpolate_run(run,1:0.1:12) for run in val]     ## The two seconds following the stimulation\n",
    "        Pair(k,newAvg)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this can be saved to be reused by the figures script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save(\"data/interpolatedData.jld2\",large_interpolated_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate statisitics per repeat\n",
    "For every single experimental repeat, we calculate a battery of statistics (the function ```compileStats``` is defined in ```code/functions/fluoRunUtilities.jl```). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyEntries = labbook[:keyEntry];\n",
    "fullStats = compileStats(full_data_dict,keyEntries)\n",
    "DataFrames.head(fullStats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics per run\n",
    "We aggregate those statistic per experimental run (each run is constituted by 4 repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_per_run = aggregate(fullStats,[:experiment,:runIdx],median);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And reformat and add some metadata to this table :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Convert the number of pulses back to integer\n",
    "stats_per_run[:nPulses_median] = convert(Array{Int},stats_per_run[:nPulses_median]);\n",
    "\n",
    "## Add some metadata columns \n",
    "stats_per_run[:cellPair]=\"\"\n",
    "stats_per_run[:genotype]=\"\"\n",
    "stats_per_run[:preNeuron]=\"\"\n",
    "stats_per_run[:postNeuron]=\"\"\n",
    "stats_per_run[:preDrug]=true\n",
    "stats_per_run[:Drug]=\"\"\n",
    "stats_per_run[:timeToDrug]= -Inf\n",
    "for i in 1:size(stats_per_run,1)\n",
    "    stats_per_run[i,:cellPair] = labbook[findfirst(keyEntries.==stats_per_run[i,:experiment]),:cellToCell]\n",
    "    stats_per_run[i,:genotype] = labbook[findfirst(keyEntries.==stats_per_run[i,:experiment]),:genotypeRegion]\n",
    "    stats_per_run[i,:preNeuron] = labbook[findfirst(keyEntries.==stats_per_run[i,:experiment]),:cellPre]\n",
    "    stats_per_run[i,:postNeuron] = labbook[findfirst(keyEntries.==stats_per_run[i,:experiment]),:cellPost]\n",
    "    if (!ismissing(labbook[findfirst(keyEntries.==stats_per_run[i,:experiment]),:Drug]))\n",
    "        stats_per_run[i,:preDrug] = (labbook[findfirst(keyEntries.==stats_per_run[i,:experiment]),\n",
    "            :timesToDrug][stats_per_run[i,:runIdx]])>Dates.Second(0)\n",
    "        stats_per_run[i,:timeToDrug] = -Int64(Dates.value(labbook[findfirst(keyEntries.==stats_per_run[i,:experiment]),\n",
    "            :timesToDrug][stats_per_run[i,:runIdx]]))/60000\n",
    "        stats_per_run[i,:Drug]=labbook[findfirst(keyEntries.==stats_per_run[i,:experiment]),:Drug]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to restrict our analysis to cell pairs for which we have a sufficient number of experiments :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calculate the number of runs per pair and select pairs with at least 3 runs\n",
    "ns = by(stats_per_run,:cellPair,df -> DataFrame(n = length(unique(df[:experiment]))))\n",
    "fullExps = ns[ns[:n].>=3,:cellPair];\n",
    "\n",
    "stats_per_run = stats_per_run[in.(Array(stats_per_run[:cellPair]),[fullExps]),:];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to categorize the cell pairs in function of their potential synaptic overlaps. For that we use the ```linesAndTypes``` table which has columns for the pre and post-synaptic innervation patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## List the cell types tested\n",
    "uniqueTypesUsed = unique(vcat(stats_per_run[:preNeuron],stats_per_run[:postNeuron]))\n",
    "sort!(uniqueTypesUsed,by= v->linesToType[findfirst(linesToType[Symbol(\"Type Description\")].==v),:Supertype] )\n",
    "\n",
    "## Parse the neuron types to define their pre/post regions\n",
    "possibleNeuropiles = [\"PB\",\"FB\",\"EB\",\"NO\",\"GA\",\"LAL\",\"rub\",\"BU\"];\n",
    "neuronTypes = OrderedDict(uniqueTypesUsed[i] =>\n",
    "                          Dict(\"innervates\" => filter(x -> contains(uniqueTypesUsed[i],x),\n",
    "                                                                possibleNeuropiles), \n",
    "                               \"pre\"=> split(linesToType[findfirst(linesToType[:,\n",
    "                                            Symbol(\"Type Description\")].==uniqueTypesUsed[i]),\n",
    "                                            Symbol(\"Pre regions\")],\",\"),\n",
    "                               \"post\" => split(linesToType[findfirst(linesToType[:,\n",
    "                                            Symbol(\"Type Description\")].==uniqueTypesUsed[i]),\n",
    "                                            Symbol(\"Post regions\")],\",\"),\n",
    "                               \"pre_fine\"=> split(linesToType[findfirst(linesToType[:,\n",
    "                                                Symbol(\"Type Description\")].==uniqueTypesUsed[i]),\n",
    "                                                Symbol(\"Pre regions fine\")],\",\"),\n",
    "                                \"post_fine\" => split(linesToType[findfirst(linesToType[:,\n",
    "                                                Symbol(\"Type Description\")].==uniqueTypesUsed[i]),\n",
    "                                                Symbol(\"Post regions fine\")],\",\"),\n",
    "                                \"short_name\" => linesToType[findfirst(linesToType[:,\n",
    "                                                    Symbol(\"Type Description\")].==uniqueTypesUsed[i]),\n",
    "                                                    Symbol(\"New Type Name\")]) for i in 1:length(uniqueTypesUsed))\n",
    "\n",
    "## Using the annotation, establish if there's a potential overlap for every pair \n",
    "stats_per_run[:overlapping]=\n",
    "[(length(intersect(neuronTypes[ty][\"pre_fine\"],\n",
    "        neuronTypes[tyPost][\"post_fine\"]))>0) for (ty,tyPost) in zip(stats_per_run[:preNeuron],\n",
    "                                                                     stats_per_run[:postNeuron])]\n",
    "\n",
    "## Is the same neuron used for recording and stimulation ?\n",
    "stats_per_run[:self]= (stats_per_run[:preNeuron].==stats_per_run[:postNeuron]);\n",
    "\n",
    "stats_per_run[:expType] = \"Non overlapping\"\n",
    "stats_per_run[stats_per_run[:overlapping],:expType] = \"Overlapping\"\n",
    "stats_per_run[stats_per_run[:self],:expType] = \"Self stimulation\"\n",
    "stats_per_run[:overlapping] =  stats_per_run[:expType].==\"Overlapping\"; ## Excluding self activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then scale a couple of variables so that inhibition spans the -1 to 0 range while excitation spans 0 to 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_per_run[:integNorm_scaled] =  scaleResponse(stats_per_run[:integNorm_median],trimming=true)\n",
    "stats_per_run[:integral_to_peak_scaled] =  scaleResponse(stats_per_run[:integral_to_peak_median],trimming=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```stats_per_run``` now looks like :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrames.head(stats_per_run,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drug experiments tables\n",
    "We then separate the parts of these tables containing the drug experiments per se (starting 5 minutes before the actual application) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting mecamylamine runs    \n",
    "mecadf = stats_per_run[(stats_per_run[:Drug].==\"Mecamylamine\") .& (stats_per_run[:timeToDrug].>-5),:]\n",
    "\n",
    "# Same thing for picrotoxin\n",
    "picrodf = stats_per_run[(stats_per_run[:Drug].==\"Picrotoxin\") .& (stats_per_run[:timeToDrug].>-5),:];\n",
    "\n",
    "## In case we want to save\n",
    "## save(\"data/drugTables.jld2\",\"mecadf\",mecadf,\"picrodf\",picrodf,\"drugStats\",drugStatsDFPerPair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics per pairs\n",
    "We now compile the statistics per cell pair (keeping the different stimulation conditions separate). The ```category_stats``` function used is in ```code/functions/fluoRunUtilities.jl```. We also scale the normalized integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_per_pair = by(stats_per_run[stats_per_run[:preDrug],:],[:cellPair,:nPulses_median],category_stats)\n",
    "stats_per_pair[:integNormScaled] = scaleResponse(stats_per_pair[:integNorm]);\n",
    "DataFrames.head(stats_per_pair,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compute the signed distance to the null distribution of responses (as described in the paper) and the significance at 0.01 and 0.005 to the table :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which statistics are included in the distance calculation\n",
    "stats_to_use = [:integNormScaled,\n",
    "                 :between_runs_corr\n",
    "               ];\n",
    "\n",
    "addDistances!(stats_per_pair,stats_to_use,:integNormScaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add a \"global significance\" which is the significance at 1% signed by the sign of the response. We also normalize the distance to the maximum response observed at 20 pulses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_per_pair[:globalSignif] =  sign.(stats_per_pair[:distance]).*stats_per_pair[:signif1]\n",
    "stats_per_pair[stats_per_pair[:globalSignif].==-0.0,:globalSignif]=0\n",
    "stats_per_pair[:distanceNorm] = stats_per_pair[:distance]./maximum(trim(abs.(stats_per_pair[stats_per_pair[:nPulses_median].<=20,:distance]),\n",
    "                                                                        prop=0.01));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a data frame restricted to the 20 pulses stimulations, as it's the one we'll be using mainly for the summaries (figures and website)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_per_pair_20 = stats_per_pair[stats_per_pair[:nPulses_median].==20,:];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then save this data for further use (not run) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#@save \"data/statTables.jld2\" stats_per_run stats_per_pair uniqueTypesUsed stats_per_pair_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exports for the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For exports, we're taking advantage of the JSON package which can translate a Julia dictionary into a json string. For ease of use in the website, we export those json as javascript variables into small .js files (those will be global variables in the website).\n",
    "- this first function is used to convert the DataFrames into dictionaries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_dataDict_per_key(pk,data_dict)\n",
    "    dat = data_dict[pk][1:min(6,end)]\n",
    "    if length(dat)==0\n",
    "        return(0)\n",
    "    else\n",
    "        dat = Dict(x[2][\"pulseNumber\"] => transformAxisArray(x[1]) for x in dat)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It uses the ```transformAxisArray``` methods defined here, that creates an AxisArray into a dictionary (hence a js variable) directly usable by plotly.js which we use for plotting in the website : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function transformAxisArray{T}(aa::AxisArray{T,1})\n",
    "    Dict(\"x\"=>axes(aa,1)[:]-axes(aa,1)[findfirst(axes(aa,1)[:].>3.0)],\"y\"=>aa)\n",
    "end\n",
    "\n",
    "transformAxisArray{T}(aa::AxisArray{T,3}) = Dict(\"x\"=>axes(aa,1)[:]-axes(aa,1)[findfirst(axes(aa,1)[:].>3.0)],\n",
    "                                                 \"y\"=>reshape(aa,(size(aa,1)*size(aa,2),size(aa,3))))\n",
    "\n",
    "transformAxisArray{T}(AA::Array{AxisArrays.AxisArray{T,1,Array{T,1},\n",
    "    Tuple{AxisArrays.Axis{:time,StepRangeLen{Float64}}}},1}) =  Dict(\"x\"=>[axes(aa,1)[:]-axes(aa,1)[findfirst(axes(aa,1)[:].>3.0)] for aa in AA],\"y\"=>AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then format and export the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting the full fluorescence and the average\n",
    "out_data = Dict(pk => get_dataDict_per_key(pk,full_data_dict) for pk in keyEntries)\n",
    "filter!((x,y) -> y!=0,out_data)\n",
    "    #writeJS(\"js/full_data.js\",\"FULL_DATA\",out_data)\n",
    "\n",
    "out_data_avg = Dict(pk => get_dataDict_per_key(pk,avg_data_dict) for pk in keyEntries)\n",
    "filter!((x,y) -> y!=0,out_data_avg)\n",
    "    #writeJS(\"js/avg_data.js\",\"AVG_DATA\",out_data_avg)\n",
    "\n",
    "## Exporting a table mapping the experiments to the cell pairs\n",
    "pairToExp = Dict(cpair => convert(Array{String},labbook[convert(Array{Bool}\n",
    "                ,labbook[:cellToCell].==cpair),:keyEntry]) for \n",
    "        cpair in unique(labbook[:cellToCell]))\n",
    "#writeJS(\"js/pairsToExp.js\",\"PAIRS_TO_EXP\",pairToExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting a supertype description table\n",
    "##Limiting to the experiments that have been done\n",
    "supertypes = unique(linesToType[:Supertype])\n",
    "\n",
    "superDict = Dict(s => unique(linesToType[(linesToType[:Supertype].==s) .& \n",
    "        [td in uniqueTypesUsed for td in linesToType[Symbol(\"Type Description\")]],Symbol(\"Type Description\")]) for \n",
    "    s in supertypes)\n",
    "superDict = filter((k,x) -> !isempty(x),superDict)\n",
    "\n",
    "#writeJS(\"js/supertypes.js\",\"SUPERTYPES\",superDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the tables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "superSummary = \n",
    "Dict(cp => Dict(string(n) => \n",
    "stats_per_pair_20[(stats_per_pair_20[:cellPair].==cp),n][1] for \n",
    "            n in [:n,:expType,:signif1,:signif5,:distanceNorm]) for\n",
    "            cp in unique(stats_per_pair_20[:cellPair]))\n",
    "\n",
    "#drugSummary = \n",
    "##Dict(cp => Dict(string(n) => \n",
    "#drugStatsDFPerPair[(drugStatsDFPerPair[:cellPair].==cp),n][1] for \n",
    "#                n in names(drugStatsDFPerPair)) for\n",
    "#            cp in unique(drugStatsDFPerPair[:cellPair]))\n",
    "\n",
    "## For now we're exporting the stats for the drug free runs\n",
    "perRunDataDict = \n",
    "Dict(exp => Dict(nP => Dict(string(n) => \n",
    "unique(stats_per_run[(stats_per_run[:experiment].==exp) .& (stats_per_run[:nPulses_median].==nP) .& (stats_per_run[:preDrug]),\n",
    "    n]) for \n",
    "                n in names(stats_per_run)) for\n",
    "    nP in stats_per_run[stats_per_run[:experiment].==exp,:nPulses_median]) for \n",
    "    exp in unique(stats_per_run[:experiment]))\n",
    "\n",
    "## Drug exports\n",
    "mecaDataDict = \n",
    "Dict(exp => Dict(string(n) => \n",
    "                 unique(mecadf[(mecadf[:experiment].==exp),n]) for \n",
    "                 n in names(mecadf)) for \n",
    "     exp in unique(mecadf[:experiment]))\n",
    "\n",
    "picroDataDict = \n",
    "Dict(exp =>  Dict(string(n) => \n",
    "                  unique(picrodf[(picrodf[:experiment].==exp),n]) for \n",
    "                  n in names(picrodf)) for \n",
    "     exp in unique(picrodf[:experiment]))\n",
    "\n",
    "## A table of drivers, used by the website\n",
    "drivers = Dict(td => convert(Array,\n",
    "        linesToType[linesToType[Symbol(\"Type Description\")].== td,:Line]) for \n",
    "                          td in unique(linesToType[Symbol(\"Type Description\")]));\n",
    "#writeJS(\"js/drivers.js\",\"DRIVERS\",drivers)\n",
    "\n",
    "#writeJS(\"js/perRunData.js\",\"PER_RUN_DATA\",perRunDataDict)\n",
    "#writeJS(\"js/neurontypes.js\",\"NEURON_TYPES\",neuronTypes)\n",
    "#writeJS(\"js/summaryData.js\",\"SUMMARY_DATA\",summaryDataDict)\n",
    "#writeJS(\"js/superSummary.js\",\"SUPER_SUMMARY\",superSummary)\n",
    "#writeJS(\"js/mecaData.js\",\"MECA_DATA\",mecaDataDict)\n",
    "#writeJS(\"js/picroData.js\",\"PICRO_DATA\",picroDataDict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
